,Q,A,unit
0,What is Machine Learning,Machine Learning is a branch of Artificial Intelligence that involves the design and development of algorithms that enable computers to capture and model behaviors based on empirical data,1
1,What does Intelligence Require,Intelligence requires knowledge and computers need to acquire knowledge to learn and solve problems,1
2,How does Data Provide Knowledge,Data provides knowledge in many cases and Machine Learning algorithms use data to learn and make predictions,1
3,Why is Machine Learning Popular,Machine Learning is a very popular area now with many recent success stories and a lot of data available,1
4,What is Logistic Regression?,Logistic regression is a classification algorithm used to assign observations to a discrete set of classes.,1
5,What problems can Logistic Regression solve?,Some examples are Email spam or not spam Online transactions Fraud or not Fraud Tumor Malignant or Benign.,1
6,How does Logistic Regression transform its output?,Logistic regression transforms its output using the logistic sigmoid function to return a probability value.,1
7,What are the types of Logistic Regression?,Binary (e.g. Tumor Malignant or Benign) and Multi-class (e.g. Cats dogs or Sheep's).,1
8,How does Logistic Regression differ from Linear Regression?,Logistic Regression uses a sigmoid function as its cost function unlike Linear Regression.,1
9,What is the hypothesis function of Logistic Regression?,The hypothesis function is σ(β₀ + β₁X) where σ is the sigmoid function.,1
10,What is Kevin Murphy's Definition of Machine Learning,Kevin Murphy defined Machine Learning in 2012 as algorithms that automatically detect patterns in data and use the uncovered patterns to predict future data or other outcomes of interest,1
11,What is Tom Mitchell's Definition of Machine Learning,Tom Mitchell defined Machine Learning in 1997 as algorithms that improve their performance at some task with experience,1
12,What is the Problem Space in Machine Learning,The problem space in Machine Learning involves feature extraction classification and end-to-end learning,1
13,What is Feature Extraction in Machine Learning,Feature extraction involves finding x corresponding to an entity or item such as an image webpage or ECG,1
14,What is Classification in Machine Learning,Classification involves finding a parameterized function that can make the right predictions denoted by f and the predictions are denoted by y,1
15,What is End-to-End Learning in Machine Learning,End-to-end learning involves learning y directly from I,1
16,What does the Machine Learning Framework Involve,The Machine Learning framework involves training testing and parameter estimation,1
17,What is Training in Machine Learning,Training involves estimating the prediction function f by minimizing the prediction error,1
18,What is Testing in Machine Learning,Testing involves applying f to unknown test samples and predicting the output value,1
19,What are the Applications of Machine Learning,Machine Learning has many applications including spam detection medical diagnosis stock trading sentiment analysis disease confirmation product recommendation loan approval face recognition and voice detection,1
22,What is the Machine Learning Framework,The Machine Learning framework involves applying a prediction function to a feature representation of the sample to get the desired output,1
23,What is the process of Training and Testing in Machine Learning,Training involves estimating the prediction function f by minimizing the prediction error while testing involves applying f to never before seen test examples and outputting predicted values,1
24,What is the Underlying Abstraction in Machine Learning,The underlying abstraction in Machine Learning is y equals f of x where x is the input y is the output and f is the prediction function,1
25,What is the difference between Regression and Time Series,Regression involves predicting a real number while time series forecasting involves predicting based on prior time-tagged data,1
26,What is the difference between Training and Testing in Machine Learning,Training is the process of making the system able to learn while testing is the process of evaluating the learned model,1
27,What is the difference between Supervised and Unsupervised Learning,Supervised learning involves inferring a function from labeled training data while unsupervised learning involves learning patterns from unlabeled data,1
28,What is Classification in Machine Learning,Classification involves predicting a class label for a given input,1
29,What are Features and Representations in Machine Learning,Features are the inputs to the prediction function while representations are the outputs of the feature extraction process,1
30,What are Samples and Points in Machine Learning,A sample is a single data point while a point is a single feature representation,1
31,What is a Learned Function or Model in Machine Learning,The learned function or model is the prediction function f that is estimated during training,1
32,What is Common Terminology in Machine Learning,Common terminology in Machine Learning includes ground truth labels predictions training and testing supervised and unsupervised features input output feature representation samples learning model and classification,1
33,What are the Assumptions in Machine Learning,Machine Learning assumes that the training set and testing set come from the same distribution and that some assumptions or bias are needed to make predictions,1
34,What is an Experiment in Machine Learning,The experiment involves splitting the data into train and test sets using train_test_split from sklearn,1
35,What is the role of Visualization in Machine Learning,Visualization involves visualizing the data in 2D or 3D to understand the relationships between the features,1
36,What is Dimensionality in Machine Learning,Machine Learning often involves working with high-dimensional data where the number of features is large,1
37,What is the Machine Learning Pipeline,The Machine Learning pipeline involves data collection data preprocessing feature generation model training and model evaluation,1
38,What is a Clear Use Case in Machine Learning,A good Machine Learning problem should have a clear use case relevant data and decision-making involved,1
39,What is ML Problem Formulation,Machine Learning problem formulation involves defining the problem statement input features predicted label and machine learning function,1
40,What is Supervised Learning in Machine Learning,Supervised learning involves inferring a function from labeled training data where the goal is to predict a target variable,1
41,Why is Data Quality Crucial in Machine Learning,Data quality is crucial in Machine Learning and noisy or low-quality data can affect the performance of the model,1
42,What is Feature Selection in Machine Learning,Feature selection is important in Machine Learning and scaling feature extraction and feature selection are required to improve model performance,1
43,What does Model Training and Testing involve,Model training and testing involve splitting the data into training and testing sets and evaluating the model performance using metrics such as accuracy precision and recall,1
44,What is a Holdout Test Set in Machine Learning,Holdout test set is a method of evaluating model performance by splitting the data into training and testing sets where the test set is used to estimate model performance,1
45,What is a Three-Way Split in Machine Learning,Three-way split involves splitting the data into training validation and testing sets where the validation set is used to tune model parameters,1
46,What is K-Fold Cross-Validation in Machine Learning,K-fold cross-validation is a method of evaluating model performance by splitting the data into k partitions where each partition is used as a validation set,1
47,What is Leave-One-Out Cross-Validation in Machine Learning,Leave-one-out cross-validation is a method of evaluating model performance by using each example as a validation set,1
48,What is Model Performance Estimation in Machine Learning,Model performance estimation involves calculating the mean performance of the model across multiple runs,1
49,What are Common Splitting Strategies in Machine Learning,Common splitting strategies include k-fold cross-validation leave-one-out cross-validation and holdout test set,1
50,How to Handle Small Datasets in Machine Learning,Small datasets require special attention and techniques such as k-fold cross-validation and leave-one-out cross-validation are used to evaluate model performance,1
51,What is Model Evaluation in Machine Learning,Model evaluation involves summarizing the performance of the model using metrics such as accuracy precision and recall and selecting the best model based on the evaluation results,1
52,What is Dimensionality Reduction?,Dimensionality reduction is the process of converting a set of data with a large number of dimensions into data with a smaller number of dimensions.,1
53,What are the benefits of Dimensionality Reduction?,The benefits of dimensionality reduction include compressing data reducing storage space requiring lesser computation time removing redundant features and potentially reducing noise.,1
54,What are the types of Dimensionality Reduction?,There are two types of dimensionality reduction: feature extraction and feature selection.,1
55,What is Feature Extraction?,Feature extraction finds new features in the data after it has been transformed from a high-dimensional space to a low-dimensional space.,1
56,What is Feature Selection?,Feature selection finds the most relevant features to a problem by obtaining a subset or key features of the original variables.,1
57,How can features be selected as a matrix multiplication?,Selecting features can be done by performing a matrix multiplication where the resulting matrix gives the linear combination of features that reduces the dimension.,1
58,What is Principal Component Analysis (PCA)?,PCA is a dimensionality reduction method based on feature extraction that transforms a data set to a lower dimension.,1
59,What is the PCA Transformation Matrix?,The PCA transformation matrix has dimension M by N and transforms each vector to a lower dimension M by a simple matrix multiply.,1
60,What is PCA as a Variance-Maximizing Technique?,PCA is a variance-maximizing technique that projects the original data onto a direction that maximizes variance.,1
61,How does PCA perform a Linear Mapping?,PCA performs a linear mapping of the original data to a lower-dimensional space such that the variance of the data in the low-dimensional representation is maximized.,1
62,How is PCA performed by Eigen-Decomposition?,PCA is performed by carrying out the eigen-decomposition of the covariance matrix.,1
63,What are Eigenvectors and Eigenvalues in PCA?,The result of PCA is a set of eigenvectors and a set of eigenvalues that can be used to describe the original data.,1
64,What are the steps involved in PCA?,The steps involved in PCA include constructing a covariance matrix performing an eigen-decomposition of that matrix and choosing the first n columns of the resulting matrix to describe the data.,1
65,What is a Covariance Matrix?,A covariance matrix is a matrix that summarizes the covariance between different variables in a multivariate distribution.,1
66,What are Eigenvalues and Eigenvectors?,Eigenvalues and eigenvectors are scalar values and vectors that describe the amount of change in a linear transformation.,1
67,What is Scikit-Learn?,Scikit-Learn is an open-source machine learning library for Python.,1
68,What does Scikit-Learn provide for Data Preprocessing?,Scikit-Learn provides tools for data preprocessing including feature scaling normalization and encoding.,1
69,What Dimensionality Reduction tools does Scikit-Learn offer?,Scikit-Learn provides tools for dimensionality reduction including PCA t-SNE and feature selection.,1
70,What tools does Scikit-Learn offer for Training/Model Building?,Scikit-Learn provides tools for building machine learning models including regression classification clustering and SVM.,1
71,What Regression tools are available in Scikit-Learn?,Scikit-Learn provides tools for regression including linear regression logistic regression and decision trees.,1
72,What Classification tools does Scikit-Learn offer?,Scikit-Learn provides tools for classification including logistic regression decision trees and SVM.,1
73,What Clustering tools does Scikit-Learn offer?,Scikit-Learn provides tools for clustering including k-means and hierarchical clustering.,1
74,What does Scikit-Learn provide for SVM?,Scikit-Learn provides tools for Support Vector Machines (SVM).,1
75,What tools does Scikit-Learn offer for Loss Function?,Scikit-Learn provides tools for calculating loss functions including mean squared error and cross-entropy.,1
76,What Optimization Algorithms are available in Scikit-Learn?,Scikit-Learn provides tools for optimization algorithms including gradient descent and stochastic gradient descent.,1
77,What Evaluation Metrics does Scikit-Learn provide?,Scikit-Learn provides tools for evaluating model performance including accuracy precision recall and F1 score.,1
78,What Transformers does Scikit-Learn provide?,Scikit-Learn provides tools for transforming data including feature scaling normalization and encoding.,1
79,What Estimators are available in Scikit-Learn?,Scikit-Learn provides tools for estimating model parameters including linear regression and decision trees.,1
80,What Predictors does Scikit-Learn offer?,Scikit-Learn provides tools for making predictions including logistic regression and decision trees.,1
81,What is the purpose of Pipeline in Scikit-Learn?,Scikit-Learn provides tools for building machine learning pipelines including chaining transformers and estimators together.,1
82,What is Q-Learning?,Q-Learning is a model-free reinforcement learning algorithm used for solving Markov Decision Processes (MDPs).,1
83,What is the Q-Function?,The Q-function is a mathematical function that maps states and actions to expected rewards.,1
84,What is a Q-Table?,A Q-table is a table that stores the Q-values for each state-action pair.,1
85,What is an Agent?,An agent is an entity that interacts with the environment and makes decisions based on the Q-function.,1
86,What is the Environment in Q-Learning?,The environment is the external world that the agent interacts with.,1
87,What are Actions in Q-Learning?,Actions are the decisions made by the agent to interact with the environment.,1
88,What are States in Q-Learning?,States are the current situation of the environment.,1
89,What are Rewards in Q-Learning?,Rewards are the feedback received by the agent for its actions.,1
90,What is the Discount Factor?,The discount factor is a parameter that determines the importance of future rewards.,1
91,What is the Exploration-Exploitation Trade-off?,The exploration-exploitation trade-off is the balance between exploring new actions and exploiting known actions.,1
92,What is the Epsilon-Greedy Algorithm?,The epsilon-greedy algorithm is a method for balancing exploration and exploitation.,1
93,What is the Q-Learning Update Rule?,The Q-learning update rule is a mathematical formula that updates the Q-values based on the agent's experiences.,1
94,What is Convergence in Q-Learning?,Convergence refers to the process of the Q-values converging to their optimal values.,1
95,What is the Optimal Policy?,The optimal policy is the policy that maximizes the expected cumulative reward.,1
96,What is the Value Function?,The value function is a mathematical function that maps states to expected rewards.,1
97,What is the Action-Value Function?,The action-value function is a mathematical function that maps states and actions to expected rewards.,1
98,What are Q-Learning Variants?,There are several variants of Q-learning including deep Q-learning double Q-learning and dueling Q-learning.,1
99,What are Deep Q-Networks?,Deep Q-networks are neural networks that approximate the Q-function.,1
100,What is Experience Replay?,Experience replay is a method for storing and replaying experiences to improve learning.,1
101,What is a Target Network?,A target network is a neural network that is used to estimate the target Q-values.,1
102,What are some applications of Q-Learning?,Q-learning has been applied to a wide range of domains including robotics game playing and finance.,1
103,What challenges does Q-Learning face?,Q-learning faces several challenges including the curse of dimensionality exploration-exploitation trade-off and convergence.,1
104,What are Q-Learning Extensions?,There are several extensions to Q-learning including multi-agent Q-learning hierarchical Q-learning and transfer learning.,1
105,How does Q-Learning compare to other algorithms?,Q-learning is compared to other reinforcement learning algorithms such as SARSA and policy gradient methods.,1
106,What are some real-world applications of Q-Learning?,Q-learning has been used in several real-world applications including autonomous vehicles recommendation systems and resource allocation.,1
107,How is Q-Learning used in Robotics?,Q-learning has been used in robotics to learn control policies for robots.,1
108,How is Q-Learning used in Game Playing?,Q-learning has been used in game playing to learn optimal policies for games such as Go and Poker.,1
109,How is Q-Learning used in Finance?,Q-learning has been used in finance to learn optimal trading policies.,1
110,How is Q-Learning used in Healthcare?,Q-learning has been used in healthcare to learn optimal treatment policies.,1
111,How is Q-Learning used in Energy Management?,Q-learning has been used in energy management to learn optimal energy consumption policies.,1
112,What are Decision Trees?,Decision Trees are a type of predictive learning algorithm used for both classification and regression.,1
113,What are the characteristics of Decision Trees?,They are non-parametric fast and efficient.,1
114,What do Decision Trees consist of?,Decision Trees consist of nodes with parent-child relationships.,1
115,What does the root node represent in a Decision Tree?,The root node represents the entire population or sample.,1
116,What are parent nodes in Decision Trees?,Parent nodes are divided into sub-nodes which are called child nodes.,1
117,What is splitting in Decision Trees?,Splitting is the process of dividing a node into two or more sub-nodes.,1
118,What are decision nodes in Decision Trees?,Decision nodes are sub-nodes that split into further sub-nodes.,1
119,What are leaf nodes in Decision Trees?,Leaf nodes are nodes that do not split.,1
120,What is pruning in Decision Trees?,Pruning is the process of removing sub-nodes of a decision node.,1
121,What are branches in a Decision Tree?,Branches are sub-sections of the entire tree.,1
122,What is the ID3 algorithm?,The ID3 algorithm is used to generate a decision tree from a dataset.,1
123,How does the ID3 algorithm start?,The ID3 algorithm begins with the original set S as the root node.,1
124,How does the ID3 algorithm select attributes?,The algorithm iterates through every unused attribute of the set S and calculates the entropy H(S) or information gain IG(S) of that attribute.,1
125,How is the attribute selected in the ID3 algorithm?,The attribute with the smallest entropy (or largest information gain) value is selected.,1
126,What happens after selecting an attribute in the ID3 algorithm?,The set S is then split by the selected attribute to produce subsets of the data.,1
127,What does the ID3 algorithm do after splitting the set S?,The algorithm continues to recurse on each subset considering only attributes never selected before.,1
128,When does the ID3 algorithm stop?,The algorithm stops when a user-defined stopping condition is reached or perfect homogeneity is obtained.,1
129,What is entropy in the context of Decision Trees?,Entropy is a measure of randomness with higher entropy indicating more random data.,1
130,What is information gain in Decision Trees?,Information gain is the decrease in entropy.,1
131,How is the variable chosen in Decision Trees?,The variable that provides the maximum entropy gain is chosen.,1
132,What is the Gini Index?,The Gini Index is a measure of variance across all classes of the data.,1
133,What does the Gini Index measure?,The Gini Index measures the impurity of the data.,1
134,How does the Gini Index change with the depth of the tree?,The Gini Index decreases to zero with an increase in the depth of the tree.,1
135,What is the CART algorithm?,The CART algorithm is a non-parametric decision tree learning technique.,1
136,What does the CART algorithm produce?,CART produces either classification or regression trees depending on the dependent variable.,1
137,How are Decision Trees formed?,Decision trees are formed by a collection of rules based on variables in the modeling data set.,1
138,How are rules selected in Decision Trees?,Rules based on variable values are selected to get the best split to differentiate observations based on the dependent variable.,1
139,What procedure is used to grow a tree in Decision Trees?,The recursive binary splitting procedure is used to grow a tree.,1
140,What is the cost function in Decision Trees?,The cost function is used to find the most homogeneous branches.,1
141,What is the cost function for regression in Decision Trees?,The cost function for regression is the sum of the squared differences between the actual and predicted values.,1
142,What are Decision Trees?,Decision Trees are a type of classification algorithm.,1
143,How popular are Decision Trees?,Decision Trees are a popular tool widely used on Kaggle.,1
144,How easy are Decision Trees to use?,Decision Trees are easy to understand and use like a flow chart.,1
145,How do Decision Trees classify data?,Decision Trees use if-else rules to classify data.,1
146,What is the Root Node in a Decision Tree?,The best features of the dataset are placed at the root of the tree.,1
147,What is Splitting in Decision Trees?,The training set is split into subsets based on the best feature.,1
148,What is Recursion in Decision Trees?,Steps 1 and 2 are repeated on each subset until leaf nodes are found.,1
149,What is the pseudo code for Decision Trees?,The pseudo code for Decision Trees involves placing the best features at the root splitting the training set and repeating the process until leaf nodes are found.,1
150,What can Splitting Criteria be based on?,The splitting criteria can be based on different factors such as weight or height.,1
151,How is the Order of Criteria chosen?,The order of criteria is chosen based on the best sequence of criteria.,1
152,What dataset is used in the experiment?,The experiment uses the Fruits dataset to classify data using a Decision Tree classifier.,1
153,What is the objective of the experiment?,The objective of the experiment is to classify data using a Decision Tree classifier.,1
154,What does a Decision Tree with Depth 2 show?,A Decision Tree with a depth of 2 is shown illustrating the classification process.,1
155,What does a Decision Tree with Depth 3 show?,A Decision Tree with a depth of 3 is also shown illustrating the classification process with more complexity.,1
156,What is the summary of Decision Trees?,Decision Trees are a simple human-understandable solution that involves finding the best tree during training and using the criteria obtained during training to classify data during testing.,1
157,What are Decision Trees?,Decision Trees are a type of classification algorithm.,1
158,How popular are Decision Trees?,Decision Trees are a popular tool widely used on Kaggle.,1
159,How easy are Decision Trees to use?,Decision Trees are easy to understand and use like a flow chart.,1
160,How do Decision Trees classify data?,Decision Trees use if-else rules to classify data.,1
161,What is the Root Node in a Decision Tree?,The best features of the dataset are placed at the root of the tree.,1
162,What is Splitting in Decision Trees?,The training set is split into subsets based on the best feature.,1
163,What is Recursion in Decision Trees?,Steps 1 and 2 are repeated on each subset until leaf nodes are found.,1
164,What is the pseudo code for Decision Trees?,The pseudo code for Decision Trees involves placing the best features at the root splitting the training set and repeating the process until leaf nodes are found.,1
165,What can Splitting Criteria be based on?,The splitting criteria can be based on different factors such as weight or height.,1
166,How is the Order of Criteria chosen?,The order of criteria is chosen based on the best sequence of criteria.,1
167,What is Entropy?,Entropy is a measure of uncertainty with higher entropy indicating more random data.,1
168,What is Information Gain?,Information gain is the decrease in entropy.,1
169,How is Entropy calculated?,Entropy is calculated using the formula H(x) = -∑P(i) log2 P(i).,1
170,What are the applications of Decision Trees?,Decision Trees can be used for classification tasks and regression tasks.,1
171,What are Ensemble Methods?,Ensemble methods are a type of machine learning algorithm that combines multiple models to improve performance.,1
172,What are the types of Ensemble Methods?,There are several types of ensemble methods including bagging boosting and random forests.,1
173,What is Bagging?,Bagging or bootstrap aggregation is a technique for reducing the variance of an estimated prediction function.,1
174,What is Bootstrap in Bagging?,Bootstrap involves randomly drawing datasets with replacement from the training data each sample the same size as the original training set.,1
175,How does Bagging work for Classification?,For classification a committee of trees each cast a vote for the predicted class.,1
176,What are Random Forests?,Random forests are an ensemble classifier that consists of many decision trees and outputs the class that is the mode of the class’s output by individual trees.,1
177,Who proposed the term "random forest" and when?,The term "random forest" was first proposed by Tin Kam Ho of Bell Labs in 1995.,1
178,What method combines Breiman’s "bagging" idea and random feature selection?,The method combines Breiman’s "bagging" idea and the random selection of features.,1
179,What is CART?,CART or classification and regression trees is a greedy algorithm that uses recursive binary splitting to build decision trees.,1
180,What cost functions are used in CART?,The cost functions used in CART include mean squared error (MSE) for regression and Gini for classification.,1
181,What is a Random Forest Classifier?,A random forest classifier is an extension to bagging that uses de-correlated trees.,1
182,How does a Random Forest Classifier select features?,Each tree in a random forest selects a subset of features (words) and selects the best from the subset.,1
183,How are words sampled in Random Forest Classifier?,The words should not be uniformly sampled but rather automatically selected based on relevance.,1
184,What is Email Classification in the context of ensemble methods?,Email classification is a common application of ensemble methods where the goal is to classify emails as spam or ham.,1
185,What are the features used in Email Classification?,The features used in email classification are 2-million dimensional (one-hot) and each tree selects a subset of features (words) to select the best from the subset.,1
186,What are Support Vector Machines?,Support Vector Machines (SVMs) are a type of classification algorithm.,1
187,How popular are SVMs?,SVMs are a popular tool widely used in machine learning.,1
188,How easy are SVMs to use?,SVMs are easy to understand and use like a flow chart.,1
189,How do SVMs classify data?,SVMs use if-else rules to classify data.,1
190,What is a Linear Classifier?,A linear classifier is a type of classifier that uses a linear decision boundary.,1
191,What is the Decision Boundary in a Linear Classifier?,The decision boundary is a hyperplane that separates the classes.,1
192,Where does Class 1 lie in relation to the Decision Boundary?,Class 1 lies on the positive side of the decision boundary.,1
193,Where does Class 0 lie in relation to the Decision Boundary?,Class 0 lies on the negative side of the decision boundary.,1
194,What is the Margin in SVMs?,The margin is the width of the band around the decision boundary without any training samples.,1
195,Why is the Margin important in SVMs?,The margin is important because it reduces the chance of misclassifying future test samples.,1
196,What is Max-Margin Classification?,Max-margin classification is a type of classification that maximizes the margin.,1
197,Why is Max-Margin Classification important?,Max-margin classification is important because it generalizes better than other types of classification.,1
198,What are Support Vectors in SVMs?,Support vectors are samples at the boundary that support the margin.,1
199,What is the summary of SVMs?,SVMs are very good at generalization.,1
200,What type of Optimization do SVMs use?,SVMs use convex optimization which means there are no local minima.,1
201,What is Text Representation?,The document discusses the importance of representing text in a meaningful way beyond just using one-hot encoding.,2
202,What is Word2Vec?,Word2Vec is a technique for representing words as vectors in a high-dimensional space such that words with similar meanings are close together.,2
203,What is Continuous Bag of Words (CBOW)?,CBOW is a variant of Word2Vec that uses a window of words to predict the missing word.,2
204,What is Skip-Gram?,Skip-Gram is another variant of Word2Vec that uses a word to predict the surrounding words in a specified window.,2
205,How is Document Representation achieved?,The document discusses how to represent documents as vectors by summing or averaging the Word2Vec vectors of all words in the document.,2
206,What is GloVe?,GloVe is a technique for representing words as vectors based on how frequently words co-occur with one another.,2
207,What are Word Vector Analogies?,The document shows how word vector analogies can be used to find relationships between words such as "king" - "man" + "woman" = "queen".,2
208,What does the Word2Vec Pre-trained Model include?,The document mentions that Google's pre-trained Word2Vec model includes word vectors for a vocabulary of 3 million words and phrases.,2
209,What is Gensim?,Gensim is a Python package that serves as an interface to Word2Vec making it easy to load the Word2Vec model.,2
210,How is Vector Similarity calculated?,The document discusses how to calculate the similarity between two word vectors using cosine similarity.,2
211,How are Word2Vec vectors visualized?,The document shows how to visualize Word2Vec vectors in 2D using techniques such as PCA or t-SNE.,2
212,What is the Case Study about?,The document presents a case study comparing the performance of Bag of Words (BoW) and Word2Vec (W2V) on a text classification task.,2
213,What are the differences between BoW and W2V?,The document highlights the differences between BoW and W2V including the fact that W2V preserves the semantics or meaning of the word.,2
214,What does the Pipeline for text classification include?,The document shows a pipeline for text classification including preprocessing building a vocabulary training a model and evaluating its performance.,2
215,What is summarized in the document?,The document summarizes the key points including the importance of representing text in a meaningful way the techniques for doing so and the applications of Word2Vec.,2
216,What is Natural Language Processing (NLP)?,NLP is a field of computer science artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages.,2
217,What is the history of NLP?,NLP has a long history with early work in the 1950s and 1960s and significant advancements in the 1980s and 1990s.,2
218,What challenges does NLP face?,NLP faces several challenges including ambiguity scale and the need for robust techniques.,2
219,What are some NLP tasks?,NLP tasks include language modeling part-of-speech (POS) tagging named entity recognition and coreference resolution.,2
220,What is Language Modeling?,Language modeling is a technique for predicting the next word in a sequence of words given the context of the previous words.,2
221,What is POS Tagging?,POS tagging is the process of assigning a part of speech (such as noun verb adjective etc.) to each word in a sentence.,2
222,What is Named Entity Recognition?,Named entity recognition is the process of identifying and classifying named entities (such as people places organizations etc.) in text.,2
223,What is Coreference Resolution?,Coreference resolution is the process of identifying all phrases that refer to the same entity in a text.,2
224,What are Parsers used for in NLP?,Parsers are used to identify the grammatical structure of a sentence including the relationships between words and phrases.,2
225,What is Syntactic Structure?,Syntactic structure refers to the arrangement of words and phrases in a sentence and is used to convey meaning.,2
226,What is Semantic Role Labeling?,Semantic role labeling is the process of identifying the roles played by entities in a sentence (such as "agent" "patient" etc.).,2
227,What is Information Extraction?,Information extraction is the process of extracting specific information from text such as names dates and locations.,2
228,What is Text Classification?,Text classification is the process of assigning a category or label to a piece of text based on its content.,2
229,What is Sentiment Analysis?,Sentiment analysis is the process of determining the emotional tone or attitude of a piece of text.,2
230,What is Deep Learning in NLP?,Deep learning is a type of machine learning that uses neural networks to analyze and interpret data and has been applied to many NLP tasks.,2
231,What is Bag of Words?,Bag of Words is a method to extract features from text documents.,2
232,What is pre-reading material about Bag of Words?,The document provides a pre-reading material on Bag of Words.,2
233,How does Bag of Words work?,Bag of Words is a method that considers a sentence or document as a 'Bag' containing words.,2
234,What are the features extracted by Bag of Words?,The features extracted from the text documents can be used for training machine learning algorithms.,2
235,What is Vocabulary in the context of Bag of Words?,The BoW model creates a vocabulary of all the unique words occurring in all the documents in the training set.,2
236,How is the unique list of words created in Bag of Words?,The unique list of words from all the documents is created.,2
237,How is the frequency of words handled in Bag of Words?,The frequency of each word in the corresponding document is inserted.,2
238,What is the dimensionality issue in Bag of Words?,The BoW approach has a dimensionality issue as the total dimension is the vocabulary size.,2
239,What is the issue of overfitting in Bag of Words?,The model can easily overfit due to the high dimensionality.,2
240,What remedy is suggested for dimensionality issue in Bag of Words?,Dimensionality reduction techniques can be used to remedy the issue.,2
241,How does Bag of Words handle semantic relations?,The BoW representation doesn't consider the semantic relation between words.,2
242,What is the role of neighbor words in Bag of Words?,The neighbor words in a sentence should be useful for predicting the target word.,2
243,What is summarized in the conclusion of Bag of Words?,The document summarizes the Bag of Words approach and its issues.,2
244,What is the importance of semantic relation in text analysis?,The document highlights the importance of considering the semantic relation between words in text analysis.,2
245,What is Word2Vec?,Word2Vec is a machine learning model used to generate Word Embeddings.,2
246,What is the purpose of Word2Vec?,Word2Vec is used to convert text to vectors and find relations between words.,2
247,How does Word2Vec work?,Word2Vec takes a large sample of textual data and finds all unique words assigning an ID to each.,2
248,What does Word2Vec do with words in vector space?,Word2Vec clusters similar or related words together in vector space.,2
249,Who developed Word2Vec?,Word2Vec was developed by a team led by Mikolov et al. while at Google.,2
250,What are Word Embeddings?,Word Embeddings are vectors that represent words in a high-dimensional space.,2
251,What properties do Word Embeddings capture?,Word Embeddings capture the relations between words such as similarity and analogy.,2
252,Can you provide an example of Word Embeddings?,Paris Beijing Tokyo Delhi and New York are all clustered together in vector space.,2
253,What are relational operations in Word2Vec?,Word2Vec can perform relational operations such as finding the most similar words.,2
254,Can you give an example of a relational operation in Word2Vec?,King - Man + Women = Queen.,2
255,What properties of words can Word2Vec extract?,Word2Vec can extract and provide the most similar words how similar are two words and pick the odd word out of a group of words.,2
256,What does Word2Vec require for training?,Word2Vec requires a large enough corpus of data to be trained effectively.,2
257,How does the size of the corpus affect Word2Vec?,The size of the corpus affects the quality of the Word Embeddings.,2
258,What is Bag-of-Words?,Bag-of-Words is a method to extract features from text documents.,2
259,How is a text document represented in Bag-of-Words?,A text document is represented as a bag of its words disregarding grammar and even word order but keeping multiplicity.,2
260,What are features in Bag-of-Words?,The features extracted from the text documents can be used for training machine learning algorithms.,2
261,What are the example documents used in Bag-of-Words?,Four documents are used as an example: "It was the best of times" "It was the worst of times" "It was the age of wisdom" and "It was the age of foolishness".,2
262,How are unique words extracted in Bag-of-Words?,The unique words from all the documents are extracted excluding punctuation.,2
263,How are documents vectorized in Bag-of-Words?,The documents are converted into vectors using the presence or absence of words as a boolean value.,2
264,What is the method of vectorization in Bag-of-Words?,The simplest method is to mark the presence of words as a boolean value 0 for absent 1 for present.,2
265,Can you provide an example of vectorization in Bag-of-Words?,The vector for the first document "It was the best of times" is [1 1 1 1 1 1 0 0 0 0].,2
266,What is TF-IDF?,TF-IDF stands for term frequency-inverse document frequency a statistical measure used to evaluate how important a word is to a document in a collection or corpus.,2
267,What is Term Frequency (TF)?,TF is a scoring of the frequency of the word in the current document.,2
268,What is Inverse Document Frequency (IDF)?,IDF is a scoring of how rare the word is across documents.,2
269,What is the IDF formula?,IDF(t) = log(N / n(t)) where N is the total number of documents and n(t) is the number of documents with term t in it.,2
270,What is the TF-IDF Score formula?,TF-IDF Score = TF * IDF.,2
271,What is the importance of TF-IDF score?,The TF-IDF score increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus.,2
272,How does normalization work in TF-IDF?,TF-IDF is used to normalize the term frequencies to address the problem of common words having high raw counts.,2
273,What is Word2Vec?,Word2Vec is a method that uses a vector to represent a word.,2
274,What is the problem with calculating word in the network directly?,Calculating word in the network directly is difficult.,2
275,How does Word2Vec solve the problem?,Word2Vec uses a vector to represent a word and the vector comes to represent the meaning of a word.,2
276,How are words represented in Word2Vec?,A vector space with several hundred dimensions (say 1000) is used to represent words.,2
277,What is one-hot encoding?,One-hot encoding is a method of representing words as vectors but it has limitations.,2
278,What is distributed representation in Word2Vec?,Word2Vec uses a distributed representation of a word where each word is represented by a distribution of weights across all elements in the vector.,2
279,What is the Skip-Gram model?,The Skip-Gram model is one of the two important models in Word2Vec which tries to predict context words out to some window size for each center word.,2
280,What is the Continuous Bag-of-Words model?,The Continuous Bag-of-Words model is another important model in Word2Vec which uses a sliding window over the text to form the input layer.,2
281,What is the training objective of Word2Vec?,The training objective is to maximize the conditional probability of observing the actual output word given the input context words.,2
282,How does Word2Vec work?,The context words form the input layer and each word is encoded in one-hot form. There is a single hidden layer where activation function amounts to summing rows in W1 and dividing by C. The output layer uses W2 to compute a score for each word in the vocabulary.,2
283,What are the advantages of Word2Vec?,Word2Vec captures relationships between words such as similarity and analogy. It can answer analogy questions like "a is to b as c is to?". It produces exceedingly good word representations that can run over billions of words.,2
284,What is Bag of Words?,A simple representation of text data where each document is represented as a bag (or a set) of its word occurrences.,2
285,What is not considered in Bag of Words?,Order of words is not considered.,2
286,How is each word represented in Bag of Words?,Each word is represented as a feature and the frequency of each word is used as the feature value.,2
287,What is TF-IDF?,Term Frequency-Inverse Document Frequency: a technique to weigh the importance of each word in a document.,2
288,What does TF measure?,TF measures the frequency of a word in a document.,2
289,What does IDF measure?,IDF measures the rarity of a word across all documents.,2
290,How is TF-IDF calculated?,TF-IDF is the product of TF and IDF.,2
291,What are stopwords?,Common words like "the" "and" "a" etc. that do not add much value to the meaning of a text.,2
292,Why remove stopwords?,Removing stopwords can help reduce the dimensionality of the feature space.,2
293,What are N-Grams?,A sequence of n consecutive words or characters.,2
294,How are N-Grams used?,N-Grams can be used to capture context and relationships between words.,2
295,What types of N-Grams can be used as features?,Unigrams bigrams trigrams etc. can be used as features.,2
296,What is demonstrated in the experiment section?,A demo of using N-Grams to represent text data.,2
297,What are some uses of N-Grams?,N-Grams can be used for various NLP tasks such as language modeling predicting next word resolving ambiguity machine translation etc.,2
298,What are some standard techniques for text representation?,Standard techniques include removing stopwords weighing words differently and using histograms (Bag of Words).,2
299,What are deeper techniques from NLP?,Deeper techniques include using N-gram representations identifying named entities and learning representations.,2
300,What is Web Scraping?,Web scraping is a technique for gathering data or information from any public website.,2
301,What can be extracted using Web Scraping?,Web scraping can extract any data that can be seen while browsing the web.,2
302,How is extracted data stored?,The extracted data can be saved to a local file or to a database in table format using Pandas library.,2
303,What is the first step in the Web Scraping workflow?,Send a request to the website and load the webpage using Requests and urllib.,2
304,How do you parse the content of a webpage?,Parse the content of the webpage for desired data using Beautiful Soup.,2
305,How is data stored after extraction?,Store the extracted data in a required format using Regular Expressions.,2
306,How to perform an HTTP request in Python?,Import the requests module in Python.,2
307,What method is used to send a request to a URL?,Send a GET request to the specified URL using requests.get().,2
308,How do you get the content of a downloaded HTML page?,Get the content of the downloaded HTML page using html_page.content.,2
309,Why can't HTML data be extracted simply through string processing?,HTML is nested and data cannot be extracted simply through string processing.,2
310,What tool is used to parse HTML data?,Use Beautiful Soup to parse the HTML data and create a tree structure.,2
311,What kind of data can be extracted using Beautiful Soup?,Extract specific data like author name title tables and description using Beautiful Soup.,2
312,How to import Beautiful Soup in Python?,Import the BeautifulSoup module in Python.,2
313,How do you parse an HTML page with Beautiful Soup?,Parse the HTML page using BeautifulSoup and store it in a variable.,2
314,How to extract text from an HTML page using Beautiful Soup?,Extract the text from the HTML page without any HTML tags using bs_object.get_text().,2
315,What is Accuracy?,Accuracy is a good measure when the target variable classes in the data are nearly balanced.,2
316,Can you give an example of Accuracy?,A model that predicts whether a new image is an apple or an orange 97% of the time correctly is a very good measure.,2
317,What are True Positives (TP) True Negatives (TN) False Positives (FP) and False Negatives (FN)?,TP TN FP and FN are the four terms used to evaluate the performance of a binary classifier.,2
318,Can you give an example of TP TN FP and FN?,In a cancer detection example TP is when a person actually has cancer and the model predicts it correctly TN is when a person does not have cancer and the model predicts it correctly FP is when a person does not have cancer but the model predicts it incorrectly and FN is when a person has cancer but the model predicts it incorrectly.,2
319,What is Precision?,Precision is a measure that tells us what proportion of patients that we diagnosed as having cancer actually had cancer.,2
320,What is the formula for Precision?,Precision = TP / (TP + FP),2
321,Can you give an example of Precision?,In a cancer example with 100 people only 5 people have cancer and the model predicts every case as cancer the precision is 5%.,2
322,What is Recall?,Recall is a measure that tells us what proportion of patients that actually had cancer was diagnosed by the algorithm as having cancer.,2
323,What is the formula for Recall?,Recall = TP / (TP + FN),2
324,Can you give an example of Recall?,In a cancer example with 100 people 5 people actually have cancer and the model predicts every case as cancer the recall is 100%.,2
325,Why is the choice of metric important?,The choice of metric is very important in evaluating the performance of a machine learning model.,2
326,Can you give an example of the importance of choosing the right metric?,In a cancer detection example precision and recall are more important than accuracy.,2
327,What is the relationship between Precision and Recall?,Precision and recall are related but they are not the same thing.,2
328,Can you give an example of the relationship between Precision and Recall?,In a cancer example a model with high precision may have low recall and a model with high recall may have low precision.,2
329,What is the conclusion about Accuracy Precision and Recall?,Accuracy precision and recall are important metrics in evaluating the performance of a machine learning model and the choice of metric depends on the specific problem and dataset.,2